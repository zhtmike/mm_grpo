export CUDA_VISIBLE_DEVICES="6,7"
export UNIFIED_REWARD_VLLM_URL="http://localhost:8090/v1"
export QWEN_VL_OCR_VLLM_URL="http://localhost:8091/v1"
export QWEN_VL_OCR_PATH="Qwen3VL"

python3 -m gerl.trainer.main_flowgrpo \
    algorithm.adv_estimator=flow_grpo \
    algorithm.global_std=False \
    data.train_files=/home/fq9hpsac/fq9hpsacuser02/gitlocal/flow_grpo/dataset/ocr/train.txt \
    data.val_files=/home/fq9hpsac/fq9hpsacuser02/gitlocal/flow_grpo/dataset/ocr/test.txt \
    data.train_batch_size=16 \
    data.val_max_samples=64 \
    data.max_prompt_length=512 \
    data.truncation=error \
    data.data_source=prompt \
    data.reward_fn='["qwenvl-ocr-vllm"]' \
    data.val_reward_fn='["unified-reward-vllm", "qwenvl-ocr-vllm"]' \
    actor_rollout_ref.model.path=/home/fq9hpsac/fq9hpsacuser02/data/model/stable-diffusion-3.5-medium \
    actor_rollout_ref.model.enable_gradient_checkpointing=True \
    actor_rollout_ref.model.lora_rank=32 \
    actor_rollout_ref.model.lora_alpha=64 \
    actor_rollout_ref.actor.optim.lr=1e-4 \
    actor_rollout_ref.actor.optim.weight_decay=0.0001 \
    actor_rollout_ref.actor.ppo_mini_batch_size=8 \
    actor_rollout_ref.actor.ppo_micro_batch_size_per_gpu=8 \
    actor_rollout_ref.actor.use_kl_loss=False \
    actor_rollout_ref.actor.kl_loss_coef=0.0 \
    actor_rollout_ref.actor.clip_ratio=1e-5 \
    actor_rollout_ref.actor.ratio_norm=True \
    actor_rollout_ref.actor.fsdp_config.param_offload=False \
    actor_rollout_ref.actor.fsdp_config.optimizer_offload=False \
    actor_rollout_ref.actor.fsdp_config.dtype=float16 \
    actor_rollout_ref.actor.fsdp_config.fsdp_size=1 \
    actor_rollout_ref.actor.policy_loss.loss_mode=flow_grpo \
    actor_rollout_ref.ref.fsdp_config.dtype=float16 \
    actor_rollout_ref.rollout.name=diffusers \
    actor_rollout_ref.rollout.n=8 \
    actor_rollout_ref.rollout.guidance_scale=4.5 \
    actor_rollout_ref.rollout.noise_level=0.8 \
    actor_rollout_ref.rollout.sde_type="cps" \
    actor_rollout_ref.rollout.sde_window_size=3 \
    actor_rollout_ref.rollout.sde_window_range="[0,5]" \
    actor_rollout_ref.rollout.dtype=float16 \
    actor_rollout_ref.rollout.free_cache_engine=False \
    reward_model.reward_manager=diffusion-batch \
    trainer.logger='["console", "wandb"]' \
    trainer.project_name='mm_grpo' \
    trainer.experiment_name='sd35_m_qwen3vl_8b_cps_guard_v2' \
    trainer.n_gpus_per_node=2 \
    trainer.nnodes=1 \
    trainer.save_freq=1000 \
    trainer.test_freq=5 \
    trainer.log_val_generations=5 \
    trainer.total_epochs=15 $@ > train_sd3_cps_guard_2p.log 2>&1 &
