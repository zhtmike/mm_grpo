Comprehensive documentation on using MM-GRPO for RL training of multi-modal generative models.

## Overview

MM-GRPO provides a flexible framework for training diffusion models using reinforcement learning. This guide covers:

- **Algorithms**: Understanding Flow-GRPO and Flow-GRPO-Fast
- **Configuration**: Setting up training configurations
- **Training**: Running and monitoring training jobs
- **Rewards**: Using and customizing reward functions
- **Async Strategies**: Leveraging asynchronous training for efficiency

## Getting Started

If you're new to MM-GRPO, start with:

1. [Installation Guide](../installation.md) - Set up your environment
2. [Quick Start](../quickstart.md) - Run your first training job

## Table of Contents

- [Algorithms](algorithms.md) - Flow-GRPO and Flow-GRPO-Fast algorithms
- [Configuration](configuration.md) - Configuration system and parameters
- [Training](training.md) - Training workflows and best practices
- [Rewards](rewards.md) - Reward functions and customization
- [Async Strategies](async-strategies.md) - Asynchronous training strategies
